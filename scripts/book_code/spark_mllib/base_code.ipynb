{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"MyApp\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Local Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Use a NumPy array as a dense vector.(recommend)\n",
    "dv1 = np.array([1.0, 0.0, 3.0])\n",
    "# Use a Python list as a dense vector.\n",
    "dv2 = [1.0, 0.0, 3.0]\n",
    "\n",
    "dv3 = Vectors.dense(1.0, 0.0, 3.0)\n",
    "\n",
    "sv1 = Vectors.sparse(3, [(0,2), (1.0, 3.0)])\n",
    "\n",
    "sv2 = Vectors.sparse(3, {0:1.0, 2:3.0})\n",
    "\n",
    "sv3 = Vectors.sparse(3, [0,2], [1.0, 3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Labeled Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "pos = LabeledPoint(1.0, Vectors.dense(1.0, 0.0, 3.0))\n",
    "\n",
    "neg = LabeledPoint(0.0, Vectors.sparse(3, [0,2], [1.0, 3.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Local Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Matrices\n",
    "# [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]\n",
    "# dense matrix,注意构造的方式是列优先的\n",
    "dense_matrix = Matrices.dense(3, 2, [1.0, 3.0, 5.0, 2.0, 4.0, 6.0])\n",
    "\n",
    "# [[9.0, 0.0], [0.0, 8.0], [0.0, 6.0]]\n",
    "# 参数依次是:行数，列数，列的第一个非0行+ \",n\"，非0行标，非0数据\n",
    "sparse_matrix = Matrices.sparse(3, 2, [0, 1, 3], [0, 2, 1], [9.0, 6.0, 8.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 生成测试文本\n",
    "sentenceData = spark.createDataFrame([(0, \"I heard about Spark and I love Spark\"), \n",
    "                                      (0, \"I wish Java could use case classes\"),\n",
    "                                      (1, \"Logistic regression models are neat\")]).toDF('label', 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|I heard about Spa...|[i, heard, about,...|\n",
      "|    0|I wish Java could...|[i, wish, java, c...|\n",
      "|    1|Logistic regressi...|[logistic, regres...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用Tokenizer把句子分解成单词\n",
    "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------------------------------------------------------------+\n",
      "|words                                        |rawFeatures                                                          |\n",
      "+---------------------------------------------+---------------------------------------------------------------------+\n",
      "|[i, heard, about, spark, and, i, love, spark]|(2000,[240,333,1105,1329,1357,1777],[1.0,1.0,2.0,2.0,1.0,1.0])       |\n",
      "|[i, wish, java, could, use, case, classes]   |(2000,[213,342,489,495,1329,1809,1967],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[logistic, regression, models, are, neat]    |(2000,[286,695,1138,1193,1604],[1.0,1.0,1.0,1.0,1.0])                |\n",
      "+---------------------------------------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用HashingTF把单词哈希成特征向量,设置哈希的桶数为2000(这里等于是可容纳的单词数)\n",
    "hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=2000)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "featurizedData.select(\"words\",\"rawFeatures\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# idf训练\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idfModel = idf.fit(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                       |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(2000,[240,333,1105,1329,1357,1777],[0.6931471805599453,0.6931471805599453,1.3862943611198906,0.5753641449035617,0.6931471805599453,0.6931471805599453])                       |0    |\n",
      "|(2000,[213,342,489,495,1329,1809,1967],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.28768207245178085,0.6931471805599453,0.6931471805599453])|0    |\n",
      "|(2000,[286,695,1138,1193,1604],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                               |1    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用IDFModel的transform方法获取TF-ITF值\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select('features', 'label').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 特征转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 生成测试数据\n",
    "df = spark.createDataFrame([(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\")], [\"id\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# string2index　特征编号是按照特征出现的频率高低来排序的\n",
    "indexer = StringIndexer(inputCol='category', outputCol='categoryIndex')\n",
    "model = indexer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| id|category|categoryIndex|\n",
      "+---+--------+-------------+\n",
      "|  0|       a|          0.0|\n",
      "|  1|       b|          2.0|\n",
      "|  2|       c|          1.0|\n",
      "|  3|       a|          0.0|\n",
      "|  4|       a|          0.0|\n",
      "|  5|       c|          1.0|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform\n",
    "indexed = model.transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|originalCategory|\n",
      "+---+----------------+\n",
      "|  0|               a|\n",
      "|  1|               b|\n",
      "|  2|               c|\n",
      "|  3|               a|\n",
      "|  4|               a|\n",
      "|  5|               c|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toString = IndexToString(inputCol='categoryIndex', outputCol='originalCategory')\n",
    "indexString = toString.transform(indexed)\n",
    "indexString.select('id', 'originalCategory').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 生成测试数据,注意df必须是key-value(tuple)类型\n",
    "df = spark.createDataFrame([(Vectors.dense(-1.0, 1.0, 1.0),),\\\n",
    "                            (Vectors.dense(-1.0, 3.0, 1.0),),\\\n",
    "                            (Vectors.dense(0.0, 5.0, 1.0),)], ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 这里的maxCategories是指的种类小于2的特征才被视为类别型特征,否则被视作连续型特征\n",
    "indexer = VectorIndexer(inputCol='features', outputCol='indexed', maxCategories=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indexerModel = indexer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose 2, features:KeysView({0: {0.0: 0, -1.0: 1}, 2: {1.0: 0}})\n"
     ]
    }
   ],
   "source": [
    "categoricalFeatures = indexerModel.categoryMaps.keys()\n",
    "print('choose '+str(len(categoricalFeatures))+\", features:\"+str(categoricalFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|      features|      indexed|\n",
      "+--------------+-------------+\n",
      "|[-1.0,1.0,1.0]|[1.0,1.0,0.0]|\n",
      "|[-1.0,3.0,1.0]|[1.0,3.0,0.0]|\n",
      "| [0.0,5.0,1.0]|[0.0,5.0,0.0]|\n",
      "+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed = indexerModel.transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 一共有VectorSlicer, RFormula, ChiSqSelector三种特征选择方法,这里使用ChiSqSelector\n",
    "from pyspark.ml.feature import ChiSqSelector, ChiSqSelectorModel\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n",
      "| id|          features|label|\n",
      "+---+------------------+-----+\n",
      "|  1|[0.0,0.0,18.0,1.0]|    1|\n",
      "|  2|[0.0,1.0,12.0,0.0]|    0|\n",
      "|  3|[1.0,0.0,15.0,0.1]|    0|\n",
      "+---+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成测试数据\n",
    "df = spark.createDataFrame([\n",
    "    (1, Vectors.dense(0.0, 0.0, 18.0, 1.0), 1),\n",
    "    (2, Vectors.dense(0.0, 1.0, 12.0, 0.0), 0),\n",
    "    (3, Vectors.dense(1.0, 0.0, 15.0, 0.1), 0)\n",
    "], ['id', 'features', 'label'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 特征选择,通过numTopFeatures方法设置选择与标签关联性最强的n个特征\n",
    "selector = ChiSqSelector(\n",
    "    numTopFeatures= 1,\n",
    "    featuresCol= 'features',\n",
    "    labelCol= 'label',\n",
    "    outputCol= 'selected-feature'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+----------------+\n",
      "| id|          features|label|selected-feature|\n",
      "+---+------------------+-----+----------------+\n",
      "|  1|[0.0,0.0,18.0,1.0]|    1|          [18.0]|\n",
      "|  2|[0.0,1.0,12.0,0.0]|    0|          [12.0]|\n",
      "|  3|[1.0,0.0,15.0,0.1]|    0|          [15.0]|\n",
      "+---+------------------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selector_model = selector.fit(df)\n",
    "result = selector_model.transform(df)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row, functions\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, HashingTF, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel, BinaryLogisticRegressionSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|         features|      label|\n",
      "+-----------------+-----------+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|\n",
      "|[5.4,3.9,1.7,0.4]|Iris-setosa|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|\n",
      "|[5.0,3.4,1.5,0.2]|Iris-setosa|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.1,1.5,0.1]|Iris-setosa|\n",
      "|[5.4,3.7,1.5,0.2]|Iris-setosa|\n",
      "|[4.8,3.4,1.6,0.2]|Iris-setosa|\n",
      "|[4.8,3.0,1.4,0.1]|Iris-setosa|\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|\n",
      "|[5.8,4.0,1.2,0.2]|Iris-setosa|\n",
      "|[5.7,4.4,1.5,0.4]|Iris-setosa|\n",
      "|[5.4,3.9,1.3,0.4]|Iris-setosa|\n",
      "|[5.1,3.5,1.4,0.3]|Iris-setosa|\n",
      "|[5.7,3.8,1.7,0.3]|Iris-setosa|\n",
      "|[5.1,3.8,1.5,0.3]|Iris-setosa|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据 Row(**_dict)--> Row(key1=value1, key2=value2)\n",
    "def f(x):\n",
    "    rel = {}\n",
    "    rel['features'] = Vectors.dense(float(x[0]), float(x[1]), float(x[2]), float(x[3]))\n",
    "    rel['label'] = str(x[4])\n",
    "    return rel\n",
    "\n",
    "data = spark.sparkContext.textFile('./iris.txt').\\\n",
    "    map(lambda line: line.split(',')).\\\n",
    "    map(lambda p: Row(**f(p))).\\\n",
    "    toDF()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签和特征增加索引\n",
    "labelIndexer = StringIndexer().\\\n",
    "    setInputCol('label').\\\n",
    "    setOutputCol('indexedLabel').\\\n",
    "    fit(data)\n",
    "\n",
    "featureIndexer = VectorIndexer().\\\n",
    "    setInputCol('features').\\\n",
    "    setOutputCol('indexedFeatures').\\\n",
    "    fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      " aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 0.8)\n",
      "family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
      "featuresCol: features column name. (default: features, current: indexedFeatures)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label, current: indexedLabel)\n",
      "lowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "lowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\n",
      "maxIter: max number of iterations (>= 0). (default: 100, current: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.3)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "upperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "upperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "# 设置LogisticRegression\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('indexedLabel').\\\n",
    "    setFeaturesCol('indexedFeatures').\\\n",
    "    setMaxIter(100).\\\n",
    "    setRegParam(0.3).\\\n",
    "    setElasticNetParam(0.8)\n",
    "\n",
    "print('params:\\n', lr.explainParams()) # 打印参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置IndexToString\n",
    "labelConverter = IndexToString().\\\n",
    "    setInputCol('prediction').\\\n",
    "    setOutputCol('predictedLabel').\\\n",
    "    setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建pipeline\n",
    "lrPipeline = Pipeline().\\\n",
    "    setStages([labelIndexer, featureIndexer, lr, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集进行模型训练\n",
    "trainingData, testData = data.randomSplit([0.7, 0.3])\n",
    "lrPipelineModel = lrPipeline.fit(trainingData)\n",
    "lrPredictions = lrPipelineModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  Iris-setosa,\n",
      "features:  [4.4,2.9,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.4,3.2,1.3,0.2],\n",
      "prob:  [0.5239524330049404,0.2760276684175376,0.20001989857752178],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.6,3.2,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.7,3.2,1.6,0.2],\n",
      "prob:  [0.5046172775706185,0.2872388125196186,0.20814390990976306],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.8,3.0,1.4,0.1],\n",
      "prob:  [0.5268542955807591,0.27837294823879616,0.19477275618044484],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.8,3.4,1.9,0.2],\n",
      "prob:  [0.4852683017985809,0.2984579700973703,0.21627372810404868],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [4.9,3.0,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.0,2.0,3.5,1.0],\n",
      "prob:  [0.31383869908964535,0.3502384105841017,0.33592289032625305],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.0,2.3,3.3,1.0],\n",
      "prob:  [0.3250576817988804,0.3445118872910511,0.33043043091006846],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-setosa,\n",
      "features:  [5.0,3.0,1.6,0.2],\n",
      "prob:  [0.5046172775706185,0.2872388125196186,0.20814390990976306],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.0,3.3,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.0,3.4,1.5,0.2],\n",
      "prob:  [0.5110667251610407,0.28349921567176023,0.20543405916719915],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.0,3.5,1.3,0.3],\n",
      "prob:  [0.5145313878447639,0.2773343290504268,0.20813428310480922],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.0,3.5,1.6,0.6],\n",
      "prob:  [0.4664740678495546,0.2909594857480172,0.24256644640242817],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.1,2.5,3.0,1.1],\n",
      "prob:  [0.3332798270914679,0.3344749184785859,0.33224525442994635],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-setosa,\n",
      "features:  [5.1,3.4,1.5,0.2],\n",
      "prob:  [0.5110667251610407,0.28349921567176023,0.20543405916719915],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.1,3.5,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.1,3.8,1.5,0.3],\n",
      "prob:  [0.5016332273507667,0.2847026791291414,0.213664093520092],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.1,3.8,1.9,0.4],\n",
      "prob:  [0.46636910070790527,0.30025692320039343,0.23337397609170132],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.2,3.4,1.4,0.2],\n",
      "prob:  [0.517512490453518,0.2797617539385136,0.20272575560796846],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.4,3.4,1.5,0.4],\n",
      "prob:  [0.4921233932728403,0.2857658121065484,0.22211079462061128],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.4,3.7,1.5,0.2],\n",
      "prob:  [0.5110667251610407,0.28349921567176023,0.20543405916719915],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-setosa,\n",
      "features:  [5.4,3.9,1.7,0.4],\n",
      "prob:  [0.47923244842531987,0.2930191316616887,0.22774841991299147],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.6,2.5,3.9,1.1],\n",
      "prob:  [0.28381245165575464,0.3592913212792248,0.35689622706502055],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-virginica,\n",
      "features:  [5.6,2.8,4.9,2.0],\n",
      "prob:  [0.1737853045617406,0.349844340623002,0.4763703548152574],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.6,3.0,4.1,1.3],\n",
      "prob:  [0.25759389398269883,0.35943995457223044,0.38296615144507085],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.6,3.0,4.5,1.5],\n",
      "prob:  [0.2237003104815697,0.3622816846620328,0.4140180048563974],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.7,2.6,3.5,1.0],\n",
      "prob:  [0.31383869908964535,0.3502384105841017,0.33592289032625305],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.7,2.8,4.1,1.3],\n",
      "prob:  [0.25759389398269883,0.35943995457223044,0.38296615144507085],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-setosa,\n",
      "features:  [5.7,4.4,1.5,0.4],\n",
      "prob:  [0.4921233932728403,0.2857658121065484,0.22211079462061128],\n",
      "predict_label: Iris-setosa\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.8,2.7,4.1,1.0],\n",
      "prob:  [0.28149447951136913,0.36674792232958947,0.3517575981590415],\n",
      "predict_label: Iris-versicolor\n",
      "label:  Iris-virginica,\n",
      "features:  [5.9,3.0,5.1,1.8],\n",
      "prob:  [0.17871172736468896,0.3618814754067879,0.459406797228523],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [5.9,3.2,4.8,1.8],\n",
      "prob:  [0.19035785012289655,0.35674988370271377,0.4528922661743896],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.0,2.2,5.0,1.5],\n",
      "prob:  [0.20209464385179168,0.37236456555270775,0.42554079059550054],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.1,2.8,4.7,1.2],\n",
      "prob:  [0.23639468036294448,0.3763899208530873,0.38721539878396827],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.3,2.5,4.9,1.5],\n",
      "prob:  [0.20628768120612875,0.3704077688966091,0.4233045498972621],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.3,3.3,6.0,2.5],\n",
      "prob:  [0.11284998762425182,0.3382926661262951,0.5488573462494529],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.4,3.1,5.5,1.8],\n",
      "prob:  [0.1640608935801225,0.36833702277371444,0.46760208364616296],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.4,3.2,4.5,1.5],\n",
      "prob:  [0.2237003104815697,0.3622816846620328,0.4140180048563974],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.5,3.0,5.2,2.0],\n",
      "prob:  [0.16294903243177097,0.3544327466378693,0.4826182209303597],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.5,3.0,5.5,1.8],\n",
      "prob:  [0.1640608935801225,0.36833702277371444,0.46760208364616296],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.5,3.0,5.8,2.2],\n",
      "prob:  [0.13261688067811506,0.3525196811211331,0.5148634382007519],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.7,3.0,5.0,1.7],\n",
      "prob:  [0.1889300389567366,0.3643984839310568,0.44667147711220667],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.7,3.1,4.4,1.4],\n",
      "prob:  [0.23558786990794964,0.3634084027031181,0.40100372738893225],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-versicolor,\n",
      "features:  [6.9,3.1,4.9,1.5],\n",
      "prob:  [0.20628768120612875,0.3704077688966091,0.4233045498972621],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [6.9,3.1,5.1,2.3],\n",
      "prob:  [0.14916042511013627,0.3386272648935927,0.512212309996271],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [7.3,2.9,6.3,1.8],\n",
      "prob:  [0.13767290054218123,0.37996427494785406,0.48236282450996476],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [7.6,3.0,6.6,2.1],\n",
      "prob:  [0.11497182872256657,0.3671968942423052,0.5178312770351282],\n",
      "predict_label: Iris-virginica\n",
      "label:  Iris-virginica,\n",
      "features:  [7.9,3.8,6.4,2.0],\n",
      "prob:  [0.12497907823492406,0.37051037593062264,0.5045105458344532],\n",
      "predict_label: Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# 输出预测结果\n",
    "preRe1 = lrPredictions.select(\n",
    "    'predictedLabel',\n",
    "    'label',\n",
    "    'features',\n",
    "    'probability').\\\n",
    "    collect()\n",
    "for item in preRe1:\n",
    "    print('label: ',str(item['label'])+',\\n'\\\n",
    "          'features: ', str(item['features'])+',\\n'\\\n",
    "          'prob: ', str(item['probability'])+',\\n'\\\n",
    "          'predict_label: '+ str(item['predictedLabel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795481829095274"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对模型进行评估\n",
    "evaluator = MulticlassClassificationEvaluator().\\\n",
    "    setLabelCol('indexedLabel').\\\n",
    "    setPredictionCol('prediction')\n",
    "\n",
    "lrAccuracy = evaluator.evaluate(lrPredictions)\n",
    "lrAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "3 X 4 CSRMatrix\n",
      "(0,2) -0.258\n",
      "(0,3) -0.2287\n",
      "(1,3) 0.3504\n",
      "Intercept: [0.8121188673353097,-0.20997333175016653,-0.6021455355851429]\n",
      " numClasses: 3\n",
      " numFeatures: 4\n"
     ]
    }
   ],
   "source": [
    "# 通过model获取模型\n",
    "lrModel = lrPipelineModel.stages[2]\n",
    "\n",
    "print('Coefficients:\\n' + str(lrModel.coefficientMatrix)+\n",
    "     \"\\nIntercept: \" + str(lrModel.interceptVector)+\n",
    "     \"\\n numClasses: \" + str(lrModel.numClasses)+\n",
    "     \"\\n numFeatures: \" + str(lrModel.numFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassificationModel\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|         features|      label|\n",
      "+-----------------+-----------+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|\n",
      "|[5.4,3.9,1.7,0.4]|Iris-setosa|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|\n",
      "|[5.0,3.4,1.5,0.2]|Iris-setosa|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.1,1.5,0.1]|Iris-setosa|\n",
      "|[5.4,3.7,1.5,0.2]|Iris-setosa|\n",
      "|[4.8,3.4,1.6,0.2]|Iris-setosa|\n",
      "|[4.8,3.0,1.4,0.1]|Iris-setosa|\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|\n",
      "|[5.8,4.0,1.2,0.2]|Iris-setosa|\n",
      "|[5.7,4.4,1.5,0.4]|Iris-setosa|\n",
      "|[5.4,3.9,1.3,0.4]|Iris-setosa|\n",
      "|[5.1,3.5,1.4,0.3]|Iris-setosa|\n",
      "|[5.7,3.8,1.7,0.3]|Iris-setosa|\n",
      "|[5.1,3.8,1.5,0.3]|Iris-setosa|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据 Row(**_dict)--> Row(key1=value1, key2=value2)\n",
    "def f(x):\n",
    "    rel = {}\n",
    "    rel['features'] = Vectors.dense(float(x[0]), float(x[1]), float(x[2]), float(x[3]))\n",
    "    rel['label'] = str(x[4])\n",
    "    return rel\n",
    "\n",
    "data = spark.sparkContext.textFile('./iris.txt').\\\n",
    "    map(lambda line: line.split(',')).\\\n",
    "    map(lambda p: Row(**f(p))).\\\n",
    "    toDF()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签和特征增加索引\n",
    "labelIndexer = StringIndexer().\\\n",
    "    setInputCol('label').\\\n",
    "    setOutputCol('indexedLabel').\\\n",
    "    fit(data)\n",
    "\n",
    "featureIndexer = VectorIndexer().\\\n",
    "    setInputCol('features').\\\n",
    "    setOutputCol('indexedFeatures').\\\n",
    "    fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置IndexToString\n",
    "labelConverter = IndexToString().\\\n",
    "    setInputCol('prediction').\\\n",
    "    setOutputCol('predictedLabel').\\\n",
    "    setLabels(labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "trainingData, testData = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建决策树模型\n",
    "dtClassifier = DecisionTreeClassifier().\\\n",
    "    setLabelCol('indexedLabel').\\\n",
    "    setFeaturesCol('indexedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-----------------+\n",
      "| predictedLabel|          label|         features|\n",
      "+---------------+---------------+-----------------+\n",
      "|    Iris-setosa|    Iris-setosa|[4.4,2.9,1.4,0.2]|\n",
      "|    Iris-setosa|    Iris-setosa|[4.5,2.3,1.3,0.3]|\n",
      "|    Iris-setosa|    Iris-setosa|[4.6,3.2,1.4,0.2]|\n",
      "|    Iris-setosa|    Iris-setosa|[4.8,3.0,1.4,0.3]|\n",
      "|    Iris-setosa|    Iris-setosa|[4.8,3.4,1.6,0.2]|\n",
      "|    Iris-setosa|    Iris-setosa|[4.8,3.4,1.9,0.2]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.0,3.5,1.3,0.3]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.1,2.5,3.0,1.1]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.4,3.0,4.5,1.5]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.4,3.9,1.3,0.4]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.4,3.9,1.7,0.4]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.5,2.3,4.0,1.3]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.5,2.4,3.7,1.0]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.5,3.5,1.3,0.2]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.6,2.5,3.9,1.1]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.6,2.7,4.2,1.3]|\n",
      "| Iris-virginica| Iris-virginica|[5.6,2.8,4.9,2.0]|\n",
      "|    Iris-setosa|    Iris-setosa|[5.7,4.4,1.5,0.4]|\n",
      "|Iris-versicolor|Iris-versicolor|[5.8,2.6,4.0,1.2]|\n",
      "+---------------+---------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建pipeline\n",
    "dtPipeline = Pipeline().\\\n",
    "    setStages([labelIndexer, featureIndexer, dtClassifier, labelConverter])\n",
    "\n",
    "dtPipelineModel = dtPipeline.fit(trainingData)\n",
    "dtPredictions = dtPipelineModel.transform(testData)\n",
    "\n",
    "dtPredictions.select('predictedLabel', 'label', 'features').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762706429373097"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator().\\\n",
    "    setLabelCol('indexedLabel').\\\n",
    "    setPredictionCol('prediction')\n",
    "\n",
    "dtAccuracy = evaluator.evaluate(dtPredictions)\n",
    "dtAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree model:\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_7f2669283bfa) of depth 4 with 15 nodes\n",
      "  If (feature 2 <= 2.5999999999999996)\n",
      "   Predict: 0.0\n",
      "  Else (feature 2 > 2.5999999999999996)\n",
      "   If (feature 3 <= 1.75)\n",
      "    If (feature 2 <= 4.95)\n",
      "     If (feature 3 <= 1.65)\n",
      "      Predict: 1.0\n",
      "     Else (feature 3 > 1.65)\n",
      "      Predict: 2.0\n",
      "    Else (feature 2 > 4.95)\n",
      "     If (feature 3 <= 1.55)\n",
      "      Predict: 2.0\n",
      "     Else (feature 3 > 1.55)\n",
      "      Predict: 1.0\n",
      "   Else (feature 3 > 1.75)\n",
      "    If (feature 2 <= 4.85)\n",
      "     If (feature 0 <= 5.95)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 5.95)\n",
      "      Predict: 2.0\n",
      "    Else (feature 2 > 4.85)\n",
      "     Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看决策树模型结构\n",
    "treeModelClassifier = dtPipelineModel.stages[2]\n",
    "print('tree model:\\n'+\n",
    "     str(treeModelClassifier.toDebugString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.clustering import KMeans, KMeansModel\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|         features|      label|\n",
      "+-----------------+-----------+\n",
      "|[5.1,3.5,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,1.4,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,1.3,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,1.5,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,1.4,0.2]|Iris-setosa|\n",
      "|[5.4,3.9,1.7,0.4]|Iris-setosa|\n",
      "|[4.6,3.4,1.4,0.3]|Iris-setosa|\n",
      "|[5.0,3.4,1.5,0.2]|Iris-setosa|\n",
      "|[4.4,2.9,1.4,0.2]|Iris-setosa|\n",
      "|[4.9,3.1,1.5,0.1]|Iris-setosa|\n",
      "|[5.4,3.7,1.5,0.2]|Iris-setosa|\n",
      "|[4.8,3.4,1.6,0.2]|Iris-setosa|\n",
      "|[4.8,3.0,1.4,0.1]|Iris-setosa|\n",
      "|[4.3,3.0,1.1,0.1]|Iris-setosa|\n",
      "|[5.8,4.0,1.2,0.2]|Iris-setosa|\n",
      "|[5.7,4.4,1.5,0.4]|Iris-setosa|\n",
      "|[5.4,3.9,1.3,0.4]|Iris-setosa|\n",
      "|[5.1,3.5,1.4,0.3]|Iris-setosa|\n",
      "|[5.7,3.8,1.7,0.3]|Iris-setosa|\n",
      "|[5.1,3.8,1.5,0.3]|Iris-setosa|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据 Row(**_dict)--> Row(key1=value1, key2=value2)\n",
    "def f(x):\n",
    "    rel = {}\n",
    "    rel['features'] = Vectors.dense(float(x[0]), float(x[1]), float(x[2]), float(x[3]))\n",
    "    rel['label'] = str(x[4])\n",
    "    return rel\n",
    "\n",
    "data = spark.sparkContext.textFile('./iris.txt').\\\n",
    "    map(lambda line: line.split(',')).\\\n",
    "    map(lambda p: Row(**f(p))).\\\n",
    "    toDF()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建聚类模型并训练\n",
    "kmeansmodel = KMeans().\\\n",
    "    setK(3).\\\n",
    "    setFeaturesCol('features').\\\n",
    "    setPredictionCol('prediction').\\\n",
    "    fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1,3.5,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[4.9,3.0,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[4.7,3.2,1.3,0.2]is predicted as clusterIris-setosa\n",
      "[4.6,3.1,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.6,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[5.4,3.9,1.7,0.4]is predicted as clusterIris-setosa\n",
      "[4.6,3.4,1.4,0.3]is predicted as clusterIris-setosa\n",
      "[5.0,3.4,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[4.4,2.9,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[4.9,3.1,1.5,0.1]is predicted as clusterIris-setosa\n",
      "[5.4,3.7,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[4.8,3.4,1.6,0.2]is predicted as clusterIris-setosa\n",
      "[4.8,3.0,1.4,0.1]is predicted as clusterIris-setosa\n",
      "[4.3,3.0,1.1,0.1]is predicted as clusterIris-setosa\n",
      "[5.8,4.0,1.2,0.2]is predicted as clusterIris-setosa\n",
      "[5.7,4.4,1.5,0.4]is predicted as clusterIris-setosa\n",
      "[5.4,3.9,1.3,0.4]is predicted as clusterIris-setosa\n",
      "[5.1,3.5,1.4,0.3]is predicted as clusterIris-setosa\n",
      "[5.7,3.8,1.7,0.3]is predicted as clusterIris-setosa\n",
      "[5.1,3.8,1.5,0.3]is predicted as clusterIris-setosa\n",
      "[5.4,3.4,1.7,0.2]is predicted as clusterIris-setosa\n",
      "[5.1,3.7,1.5,0.4]is predicted as clusterIris-setosa\n",
      "[4.6,3.6,1.0,0.2]is predicted as clusterIris-setosa\n",
      "[5.1,3.3,1.7,0.5]is predicted as clusterIris-setosa\n",
      "[4.8,3.4,1.9,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.0,1.6,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.4,1.6,0.4]is predicted as clusterIris-setosa\n",
      "[5.2,3.5,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[5.2,3.4,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[4.7,3.2,1.6,0.2]is predicted as clusterIris-setosa\n",
      "[4.8,3.1,1.6,0.2]is predicted as clusterIris-setosa\n",
      "[5.4,3.4,1.5,0.4]is predicted as clusterIris-setosa\n",
      "[5.2,4.1,1.5,0.1]is predicted as clusterIris-setosa\n",
      "[5.5,4.2,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[4.9,3.1,1.5,0.1]is predicted as clusterIris-setosa\n",
      "[5.0,3.2,1.2,0.2]is predicted as clusterIris-setosa\n",
      "[5.5,3.5,1.3,0.2]is predicted as clusterIris-setosa\n",
      "[4.9,3.1,1.5,0.1]is predicted as clusterIris-setosa\n",
      "[4.4,3.0,1.3,0.2]is predicted as clusterIris-setosa\n",
      "[5.1,3.4,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.5,1.3,0.3]is predicted as clusterIris-setosa\n",
      "[4.5,2.3,1.3,0.3]is predicted as clusterIris-setosa\n",
      "[4.4,3.2,1.3,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.5,1.6,0.6]is predicted as clusterIris-setosa\n",
      "[5.1,3.8,1.9,0.4]is predicted as clusterIris-setosa\n",
      "[4.8,3.0,1.4,0.3]is predicted as clusterIris-setosa\n",
      "[5.1,3.8,1.6,0.2]is predicted as clusterIris-setosa\n",
      "[4.6,3.2,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[5.3,3.7,1.5,0.2]is predicted as clusterIris-setosa\n",
      "[5.0,3.3,1.4,0.2]is predicted as clusterIris-setosa\n",
      "[7.0,3.2,4.7,1.4]is predicted as clusterIris-versicolor\n",
      "[6.4,3.2,4.5,1.5]is predicted as clusterIris-versicolor\n",
      "[6.9,3.1,4.9,1.5]is predicted as clusterIris-versicolor\n",
      "[5.5,2.3,4.0,1.3]is predicted as clusterIris-versicolor\n",
      "[6.5,2.8,4.6,1.5]is predicted as clusterIris-versicolor\n",
      "[5.7,2.8,4.5,1.3]is predicted as clusterIris-versicolor\n",
      "[6.3,3.3,4.7,1.6]is predicted as clusterIris-versicolor\n",
      "[4.9,2.4,3.3,1.0]is predicted as clusterIris-versicolor\n",
      "[6.6,2.9,4.6,1.3]is predicted as clusterIris-versicolor\n",
      "[5.2,2.7,3.9,1.4]is predicted as clusterIris-versicolor\n",
      "[5.0,2.0,3.5,1.0]is predicted as clusterIris-versicolor\n",
      "[5.9,3.0,4.2,1.5]is predicted as clusterIris-versicolor\n",
      "[6.0,2.2,4.0,1.0]is predicted as clusterIris-versicolor\n",
      "[6.1,2.9,4.7,1.4]is predicted as clusterIris-versicolor\n",
      "[5.6,2.9,3.6,1.3]is predicted as clusterIris-versicolor\n",
      "[6.7,3.1,4.4,1.4]is predicted as clusterIris-versicolor\n",
      "[5.6,3.0,4.5,1.5]is predicted as clusterIris-versicolor\n",
      "[5.8,2.7,4.1,1.0]is predicted as clusterIris-versicolor\n",
      "[6.2,2.2,4.5,1.5]is predicted as clusterIris-versicolor\n",
      "[5.6,2.5,3.9,1.1]is predicted as clusterIris-versicolor\n",
      "[5.9,3.2,4.8,1.8]is predicted as clusterIris-versicolor\n",
      "[6.1,2.8,4.0,1.3]is predicted as clusterIris-versicolor\n",
      "[6.3,2.5,4.9,1.5]is predicted as clusterIris-versicolor\n",
      "[6.1,2.8,4.7,1.2]is predicted as clusterIris-versicolor\n",
      "[6.4,2.9,4.3,1.3]is predicted as clusterIris-versicolor\n",
      "[6.6,3.0,4.4,1.4]is predicted as clusterIris-versicolor\n",
      "[6.8,2.8,4.8,1.4]is predicted as clusterIris-versicolor\n",
      "[6.7,3.0,5.0,1.7]is predicted as clusterIris-versicolor\n",
      "[6.0,2.9,4.5,1.5]is predicted as clusterIris-versicolor\n",
      "[5.7,2.6,3.5,1.0]is predicted as clusterIris-versicolor\n",
      "[5.5,2.4,3.8,1.1]is predicted as clusterIris-versicolor\n",
      "[5.5,2.4,3.7,1.0]is predicted as clusterIris-versicolor\n",
      "[5.8,2.7,3.9,1.2]is predicted as clusterIris-versicolor\n",
      "[6.0,2.7,5.1,1.6]is predicted as clusterIris-versicolor\n",
      "[5.4,3.0,4.5,1.5]is predicted as clusterIris-versicolor\n",
      "[6.0,3.4,4.5,1.6]is predicted as clusterIris-versicolor\n",
      "[6.7,3.1,4.7,1.5]is predicted as clusterIris-versicolor\n",
      "[6.3,2.3,4.4,1.3]is predicted as clusterIris-versicolor\n",
      "[5.6,3.0,4.1,1.3]is predicted as clusterIris-versicolor\n",
      "[5.5,2.5,4.0,1.3]is predicted as clusterIris-versicolor\n",
      "[5.5,2.6,4.4,1.2]is predicted as clusterIris-versicolor\n",
      "[6.1,3.0,4.6,1.4]is predicted as clusterIris-versicolor\n",
      "[5.8,2.6,4.0,1.2]is predicted as clusterIris-versicolor\n",
      "[5.0,2.3,3.3,1.0]is predicted as clusterIris-versicolor\n",
      "[5.6,2.7,4.2,1.3]is predicted as clusterIris-versicolor\n",
      "[5.7,3.0,4.2,1.2]is predicted as clusterIris-versicolor\n",
      "[5.7,2.9,4.2,1.3]is predicted as clusterIris-versicolor\n",
      "[6.2,2.9,4.3,1.3]is predicted as clusterIris-versicolor\n",
      "[5.1,2.5,3.0,1.1]is predicted as clusterIris-versicolor\n",
      "[5.7,2.8,4.1,1.3]is predicted as clusterIris-versicolor\n",
      "[6.3,3.3,6.0,2.5]is predicted as clusterIris-virginica\n",
      "[5.8,2.7,5.1,1.9]is predicted as clusterIris-virginica\n",
      "[7.1,3.0,5.9,2.1]is predicted as clusterIris-virginica\n",
      "[6.3,2.9,5.6,1.8]is predicted as clusterIris-virginica\n",
      "[6.5,3.0,5.8,2.2]is predicted as clusterIris-virginica\n",
      "[7.6,3.0,6.6,2.1]is predicted as clusterIris-virginica\n",
      "[4.9,2.5,4.5,1.7]is predicted as clusterIris-virginica\n",
      "[7.3,2.9,6.3,1.8]is predicted as clusterIris-virginica\n",
      "[6.7,2.5,5.8,1.8]is predicted as clusterIris-virginica\n",
      "[7.2,3.6,6.1,2.5]is predicted as clusterIris-virginica\n",
      "[6.5,3.2,5.1,2.0]is predicted as clusterIris-virginica\n",
      "[6.4,2.7,5.3,1.9]is predicted as clusterIris-virginica\n",
      "[6.8,3.0,5.5,2.1]is predicted as clusterIris-virginica\n",
      "[5.7,2.5,5.0,2.0]is predicted as clusterIris-virginica\n",
      "[5.8,2.8,5.1,2.4]is predicted as clusterIris-virginica\n",
      "[6.4,3.2,5.3,2.3]is predicted as clusterIris-virginica\n",
      "[6.5,3.0,5.5,1.8]is predicted as clusterIris-virginica\n",
      "[7.7,3.8,6.7,2.2]is predicted as clusterIris-virginica\n",
      "[7.7,2.6,6.9,2.3]is predicted as clusterIris-virginica\n",
      "[6.0,2.2,5.0,1.5]is predicted as clusterIris-virginica\n",
      "[6.9,3.2,5.7,2.3]is predicted as clusterIris-virginica\n",
      "[5.6,2.8,4.9,2.0]is predicted as clusterIris-virginica\n",
      "[7.7,2.8,6.7,2.0]is predicted as clusterIris-virginica\n",
      "[6.3,2.7,4.9,1.8]is predicted as clusterIris-virginica\n",
      "[6.7,3.3,5.7,2.1]is predicted as clusterIris-virginica\n",
      "[7.2,3.2,6.0,1.8]is predicted as clusterIris-virginica\n",
      "[6.2,2.8,4.8,1.8]is predicted as clusterIris-virginica\n",
      "[6.1,3.0,4.9,1.8]is predicted as clusterIris-virginica\n",
      "[6.4,2.8,5.6,2.1]is predicted as clusterIris-virginica\n",
      "[7.2,3.0,5.8,1.6]is predicted as clusterIris-virginica\n",
      "[7.4,2.8,6.1,1.9]is predicted as clusterIris-virginica\n",
      "[7.9,3.8,6.4,2.0]is predicted as clusterIris-virginica\n",
      "[6.4,2.8,5.6,2.2]is predicted as clusterIris-virginica\n",
      "[6.3,2.8,5.1,1.5]is predicted as clusterIris-virginica\n",
      "[6.1,2.6,5.6,1.4]is predicted as clusterIris-virginica\n",
      "[7.7,3.0,6.1,2.3]is predicted as clusterIris-virginica\n",
      "[6.3,3.4,5.6,2.4]is predicted as clusterIris-virginica\n",
      "[6.4,3.1,5.5,1.8]is predicted as clusterIris-virginica\n",
      "[6.0,3.0,4.8,1.8]is predicted as clusterIris-virginica\n",
      "[6.9,3.1,5.4,2.1]is predicted as clusterIris-virginica\n",
      "[6.7,3.1,5.6,2.4]is predicted as clusterIris-virginica\n",
      "[6.9,3.1,5.1,2.3]is predicted as clusterIris-virginica\n",
      "[5.8,2.7,5.1,1.9]is predicted as clusterIris-virginica\n",
      "[6.8,3.2,5.9,2.3]is predicted as clusterIris-virginica\n",
      "[6.7,3.3,5.7,2.5]is predicted as clusterIris-virginica\n",
      "[6.7,3.0,5.2,2.3]is predicted as clusterIris-virginica\n",
      "[6.3,2.5,5.0,1.9]is predicted as clusterIris-virginica\n",
      "[6.5,3.0,5.2,2.0]is predicted as clusterIris-virginica\n",
      "[6.2,3.4,5.4,2.3]is predicted as clusterIris-virginica\n",
      "[5.9,3.0,5.1,1.8]is predicted as clusterIris-virginica\n"
     ]
    }
   ],
   "source": [
    "# 对数据集进行分类\n",
    "results = kmeansmodel.transform(data).collect()\n",
    "for item in results:\n",
    "    print(str(item[0]) + 'is predicted as cluster' + str(item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.006 3.418 1.464 0.244]\n",
      "[6.85       3.07368421 5.74210526 2.07105263]\n",
      "[5.9016129  2.7483871  4.39354839 1.43387097]\n"
     ]
    }
   ],
   "source": [
    "# 获取聚类中心情况\n",
    "results2 = kmeansmodel.clusterCenters()\n",
    "for item in results2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.94084142614648"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算误差平方和,用于在k值未知的情况下选取合适的k值\n",
    "kmeansmodel.computeCost(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
